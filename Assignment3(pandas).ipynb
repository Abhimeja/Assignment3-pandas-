{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d8a77229-2934-472d-92ba-19f915f3747c",
   "metadata": {},
   "source": [
    "Q1. Write a code to print the data present in the second row of the dataframe, df.\n",
    "\n",
    "Consider following code to answer further questions:\n",
    "import pandas as pd\n",
    "course_name = [‘Data Science’, ‘Machine Learning’, ‘Big Data’, ‘Data Engineer’]\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {‘course_name’ : course_name, ‘duration’ : duration})\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2bfbd83-6a98-4b50-b4dd-ae2a6cb6c241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Course_name  Duration\n",
      "0      Data Science         2\n",
      "1  Machine Learning         3\n",
      "2          Big Data         6\n",
      "3     Data Engineer         4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Course_name':['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer'],\n",
    "                'Duration':[2,3,6,4]\n",
    "                })\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6a1288e-e148-4843-8609-5481eb6c37df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course_name    Machine Learning\n",
      "Duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "second_row_data = df.iloc[1]\n",
    "print(second_row_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40160f72-1267-445b-945f-8ae669f17be3",
   "metadata": {},
   "source": [
    "To print the data present in the second row of the DataFrame \"df\", you can use the \".iloc\" attribute. In Python, indices start from 0, so to access the second row, you would use index 1."
   ]
  },
  {
   "cell_type": "raw",
   "id": "aeeacf78-b2bb-4414-970b-96a044300afa",
   "metadata": {},
   "source": [
    "Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e421b-137a-4a02-af21-857d6e17280a",
   "metadata": {},
   "source": [
    "In pandas, the loc and iloc functions are used to access and retrieve data from a DataFrame, but they have some key differences in how they work:\n",
    "\n",
    "1.'loc': The loc function is primarily label-based. It is used to access data using the labels of rows and columns. You can pass row and column labels to loc to select specific rows and columns, or use slices or boolean conditions to filter the data. The syntax for loc is df.loc[row_label, column_label] or df.loc[row_label, column_label_list]. It includes the last element when using slices.\n",
    "\n",
    "Example usage of 'loc':"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d5b90ef-7b6f-44e6-a16e-af810ee5dc07",
   "metadata": {},
   "source": [
    "# Accessing a specific cell by row and column label\n",
    "value = df.loc[row_label, column_label]\n",
    "\n",
    "# Accessing a subset of rows and all columns\n",
    "subset = df.loc[row_label_list, :]\n",
    "\n",
    "# Accessing a subset of rows and columns\n",
    "subset = df.loc[row_label_list, column_label_list]\n",
    "\n",
    "# Accessing rows based on a boolean condition\n",
    "subset = df.loc[df['column'] > 5, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2be058-ecb3-484b-916a-6a48609c6315",
   "metadata": {},
   "source": [
    "2.'iloc': The iloc function is primarily integer-based. It is used to access data using integer indices of rows and columns. You can pass integer indices or slices to iloc to select specific rows and columns. The syntax for iloc is df.iloc[row_index, column_index] or df.iloc[row_index, column_index_list]. It excludes the last element when using slices.\n",
    "\n",
    "Example usage of iloc:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c3ddd92-8de2-4d5e-ad31-be7bdea8239e",
   "metadata": {},
   "source": [
    "# Accessing a specific cell by row and column index\n",
    "value = df.iloc[row_index, column_index]\n",
    "\n",
    "# Accessing a subset of rows and all columns\n",
    "subset = df.iloc[row_index_start:row_index_end, :]\n",
    "\n",
    "# Accessing a subset of rows and columns\n",
    "subset = df.iloc[row_index_list, column_index_list]\n",
    "\n",
    "# Accessing rows based on a boolean condition\n",
    "subset = df.iloc[df['column'] > 5, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4803cb03-55a2-4ed2-bf0f-c3d8fb3d26a7",
   "metadata": {},
   "source": [
    "The main difference between loc and iloc is that loc uses label-based indexing, whereas iloc uses integer-based indexing. Therefore, loc is used when you want to access data by labels, while iloc is used when you want to access data by integer indices."
   ]
  },
  {
   "cell_type": "raw",
   "id": "25148b93-0c7c-4946-b4db-d532b056dd31",
   "metadata": {},
   "source": [
    "Q3. Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df\n",
    "then find the output for both new_df.loc[2] and new_df.iloc[2].\n",
    "\n",
    "Did you observe any difference in both the outputs? If so then explain it.\n",
    "Consider the below code to answer further questions:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae54ef0-133e-4243-aa5b-8d84087a197a",
   "metadata": {},
   "source": [
    "To reindex the given DataFrame df1 using the variable reindex = [3, 0, 1, 2] and store it in the variable new_df, you can use the reindex function in pandas. Then you can retrieve the output for both new_df.loc[2] and new_df.iloc[2] to observe any differences.\n",
    "\n",
    "Here's the code to achieve that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbdd1b91-8edb-4a14-a250-c690f3a1f7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for new_df.loc[2]:\n",
      "column_1    0.998522\n",
      "column_2    0.421391\n",
      "column_3    0.644624\n",
      "column_4    0.955271\n",
      "column_5    0.436705\n",
      "column_6    0.140970\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "Output for new_df.iloc[2]:\n",
      "column_1    0.970464\n",
      "column_2    0.470229\n",
      "column_3    0.743775\n",
      "column_4    0.674579\n",
      "column_5    0.248686\n",
      "column_6    0.854871\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "# Creating a DataFrame\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Reindexing the DataFrame\n",
    "reindex = [3, 0, 1, 2]\n",
    "new_df = df1.reindex(reindex)\n",
    "\n",
    "# Accessing the output for new_df.loc[2]\n",
    "output_loc = new_df.loc[2]\n",
    "print(\"Output for new_df.loc[2]:\")\n",
    "print(output_loc)\n",
    "\n",
    "# Accessing the output for new_df.iloc[2]\n",
    "output_iloc = new_df.iloc[2]\n",
    "print(\"\\nOutput for new_df.iloc[2]:\")\n",
    "print(output_iloc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5291ac-a5e2-4cce-af52-52a4a1917f5b",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "The output for new_df.loc[2] and new_df.iloc[2] are different.\n",
    "\n",
    "** new_df.loc[2] returns the row with label 2 from the new_df DataFrame, preserving the original index labels. It matches the row with the label 2 from the original DataFrame (df1).\n",
    "\n",
    "** new_df.iloc[2] returns the row at index 2 in the new_df DataFrame, using integer-based indexing. It does not consider the original index labels and instead uses the reindexed index positions.\n",
    "\n",
    "In the given code, after reindexing df1 with [3, 0, 1, 2], the row originally at index 2 in df1 now becomes the row at index 1 in new_df. Hence, when accessing new_df.loc[2], it returns the row at label 2 in new_df, whereas new_df.iloc[2] returns the row at index 2 in new_df, which corresponds to the row at label 1 in the original df1.\n",
    "\n",
    "Therefore, the difference in output arises due to the distinction between label-based indexing (loc) and integer-based indexing (iloc)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4acf5fc-e515-4311-bf57-0a05ed4d1553",
   "metadata": {},
   "source": [
    "Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "(i) mean of each and every column present in the dataframe.\n",
    "(ii) standard deviation of column, ‘column_2’\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7941a3d3-c747-48a2-8555-7fe52c04ec5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      "column_1    0.683559\n",
      "column_2    0.422462\n",
      "column_3    0.608811\n",
      "column_4    0.572995\n",
      "column_5    0.379082\n",
      "column_6    0.603310\n",
      "dtype: float64\n",
      "\n",
      "Standard deviation of column:\n",
      "0.09413747469298855\n"
     ]
    }
   ],
   "source": [
    "column_means=df1.mean()\n",
    "print('Mean of each column:')\n",
    "print(column_means)\n",
    "\n",
    "column_2_std=df1['column_2'].std()\n",
    "print('\\nStandard deviation of column:')\n",
    "print(column_2_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9277aeb-4261-4d96-952e-c50626d576e2",
   "metadata": {},
   "source": [
    "Q5. Replace the data present in the second row of column, ‘column_2’ by a string variable then find the\n",
    "mean of column, column_2.\n",
    "If you are getting errors in executing it then explain why.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8895ed6-313f-4857-9169-6d257590e870",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m df1\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_value\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calculating the mean of 'column_2'\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m column_2_mean \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, column_2_mean)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "# Trying to replace the data in the second row of 'column_2' with a string\n",
    "df1.loc[2, 'column_2'] = 'string_value'\n",
    "\n",
    "# Calculating the mean of 'column_2'\n",
    "column_2_mean = df1['column_2'].mean()\n",
    "print(\"Mean of 'column_2':\", column_2_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3aecf-14a8-405d-9954-82a5b18b2516",
   "metadata": {},
   "source": [
    "The error message indicates that the string value 'string_value' cannot be converted to a float, which is the expected data type for numerical operations such as calculating the mean.\n",
    "\n",
    "To avoid this error, you should replace the data with a valid numeric value. If you want to represent a missing or non-numeric value, you can use NaN (Not a Number), which is a special value in pandas to indicate missing or undefined data.\n",
    "\n",
    "Here's an example code snippet that replaces the data in the second row of 'column_2' with NaN and calculates the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbba9ebf-a8f5-4df1-9f15-bc52e5f1914c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 'column_2': 0.4226765411053227\n"
     ]
    }
   ],
   "source": [
    "# Replacing the data in the second row of 'column_2' with NaN\n",
    "df1.loc[2, 'column_2'] = np.nan\n",
    "\n",
    "# Calculating the mean of 'column_2' (excluding NaN values)\n",
    "column_2_mean = df1['column_2'].mean()\n",
    "print(\"Mean of 'column_2':\", column_2_mean)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8883f56-9fa2-494a-b41e-b935f539c4d9",
   "metadata": {},
   "source": [
    "Q6. What do you understand about the windows function in pandas and list the types of windows\n",
    "functions?\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52acb6b7-851d-4bbc-82b9-4b36529fed53",
   "metadata": {},
   "source": [
    "In pandas, the window functions provide a way to perform calculations on a specific window or subset of data within a DataFrame. These functions are especially useful for tasks such as rolling calculations, cumulative calculations, and various statistical analyses.\n",
    "\n",
    "The window functions in pandas can be accessed through the rolling(), expanding(), and ewm() methods. Here's a brief overview of each type of window function:\n",
    "\n",
    "1.Rolling Windows:\n",
    "\n",
    "a.The rolling() function creates a window of a fixed size and performs calculations on that window as it moves along the data.\n",
    "\n",
    "b.Common calculations include moving averages, rolling sums, and standard deviations.\n",
    "\n",
    "c.Rolling windows can be applied to both DataFrame and Series objects.\n",
    "\n",
    "d.Example: df.rolling(window=3).mean()\n",
    "\n",
    "2.Expanding Windows:\n",
    "\n",
    "a.The expanding() function creates a window that expands over time, starting from the beginning of the data and incorporating more observations as it progresses.\n",
    "\n",
    "b.It calculates statistics on the entire expanding window, including all previous observations.\n",
    "\n",
    "c.Common calculations include cumulative sums, cumulative products, and exponentially weighted moving averages.\n",
    "\n",
    "d.Expanding windows can be applied to both DataFrame and Series objects.\n",
    "\n",
    "e.Example: df.expanding().sum()\n",
    "\n",
    "3.Exponentially Weighted Windows:\n",
    "\n",
    "a.The ewm() function calculates exponentially weighted statistics over a specified window.\n",
    "\n",
    "b.It assigns weights to observations in the window based on an exponential decay factor, giving more weight to recent observations.\n",
    "\n",
    "c.Common calculations include exponentially weighted moving averages and exponentially weighted standard deviations.\n",
    "\n",
    "d.Exponentially weighted windows can be applied to both DataFrame and Series objects.\n",
    "\n",
    "e.Example: df.ewm(span=3).mean()\n",
    "\n",
    "These window functions offer flexibility in performing various calculations on subsets of data within a DataFrame, allowing for efficient analysis and exploration of time series and other ordered data.\n",
    "\n",
    "It's important to note that when using window functions, it's crucial to consider the window size, which determines the number of data points included in each calculation. The appropriate window size depends on the specific analysis and the characteristics of the data being analyzed."
   ]
  },
  {
   "cell_type": "raw",
   "id": "df7fec81-fce2-4764-b44e-53dd842bdfa6",
   "metadata": {},
   "source": [
    "Q7. Write a code to print only the current month and year at the time of answering this question.\n",
    "[Hint: Use pandas.datetime function]\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0805747-0d4b-4aec-be66-9c3d89a2b5df",
   "metadata": {},
   "source": [
    "To print the current month and year, you can use the datetime module from the pandas library in Python. The datetime module provides various functions to work with dates and times.\n",
    "\n",
    "Here's the code to print the current month and year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75ba9641-33ea-458b-b549-257770a8893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Month: 7\n",
      "Current Year: 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84/1034775868.py:2: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  current_date=pd.datetime.now()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "current_date=pd.datetime.now()\n",
    "current_month=current_date.month\n",
    "current_year=current_date.year\n",
    "# Print the current month and year\n",
    "print(\"Current Month:\", current_month)\n",
    "print(\"Current Year:\", current_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f775a-d8f3-42fb-90ab-c4ee63bd1c79",
   "metadata": {},
   "source": [
    "The pd.datetime.now() function retrieves the current date and time. Then, we extract the month and year using the month and year attributes of the datetime object.\n",
    "\n",
    "Note that the pd.datetime function is used to create a datetime object within the pandas library. However, starting from pandas version 1.3.0, the recommended way to create a datetime object is to use the pd.Timestamp function. So, for the above code, you can also replace pd.datetime.now() with pd.Timestamp.now() for better compatibility with the latest versions of pandas."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbb116c6-001c-495c-97aa-65aecb73e826",
   "metadata": {},
   "source": [
    "Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and\n",
    "calculates the difference between them in days, hours, and minutes using Pandas time delta. The\n",
    "program should prompt the user to enter the dates and display the result.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859a4449-6942-45cb-8cd5-80642f2a17e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the first date (YYYY-MM-DD): 2023-07-04\n",
      "Enter the Second date (YYYY-MM-DD): 2023-07-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between the two dates:\n",
      "Days: 6\n",
      "Hours: 0\n",
      "Minutes: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "date1=input(\"Enter the first date (YYYY-MM-DD):\")\n",
    "date2=input(\"Enter the Second date (YYYY-MM-DD):\")\n",
    "\n",
    "# Convert the input strings to pandas Timestamp objects\n",
    "timestamp1 = pd.Timestamp(date1)\n",
    "timestamp2 = pd.Timestamp(date2)\n",
    "\n",
    "# Calculate the difference between the two dates using pandas Timedelta\n",
    "time_difference=timestamp2-timestamp1\n",
    "\n",
    "# Extract the days, hours, and minutes from the time difference\n",
    "days=time_difference.days\n",
    "hours=time_difference.seconds//3600\n",
    "minutes=(time_difference.seconds/60)%60\n",
    "\n",
    "# Display the result\n",
    "print(\"Difference between the two dates:\")\n",
    "print(\"Days:\", days)\n",
    "print(\"Hours:\", hours)\n",
    "print(\"Minutes:\", minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c510f9d9-097b-4e11-8f34-a12229f4385e",
   "metadata": {},
   "source": [
    "In this program, the user is prompted to enter two dates in the format YYYY-MM-DD. The input strings are converted to pandas Timestamp objects using pd.Timestamp(). Then, the difference between the two dates is calculated using timestamp2 - timestamp1, resulting in a pandas Timedelta object.\n",
    "\n",
    "The Timedelta object contains the difference in days, seconds, and microseconds. We extract the number of days using the days attribute of the Timedelta object. For the hours and minutes, we perform calculations using the seconds attribute of the Timedelta object. The number of seconds is divided by 3600 to get the hours and by 60 to get the minutes.\n",
    "\n",
    "Finally, the program displays the difference between the two dates in terms of days, hours, and minutes."
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc33c9ed-0ce6-4d16-aae3-1d15d25b0569",
   "metadata": {},
   "source": [
    "Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified\n",
    "column to a categorical data type. The program should prompt the user to enter the file path, column\n",
    "name, and category order, and then display the sorted data.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b6fc340-1fa3-4389-be20-d7de652c0bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file path of the CSV file:  players_data.csv\n",
      "Enter the name of the column to convert:  Player\n",
      "Enter the category order (comma-separated):  Age\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Data:\n",
      "      Rk Player Pos Age   Tm   G  GS    MP   FG  FGA  ...   FT%  ORB  DRB  \\\n",
      "0      1    NaN  PF  24  NYK  68  22  1287  152  331  ...  .784   79  222   \n",
      "1      2    NaN  SG  20  MEM  30   0   248   35   86  ...  .609    9   19   \n",
      "2      3    NaN   C  21  OKC  70  67  1771  217  399  ...  .502  199  324   \n",
      "3      4    NaN  PF  28  MIN  17   0   215   19   44  ...  .579   23   54   \n",
      "4      5    NaN  SG  29  TOT  78  72  2502  375  884  ...  .843   27  220   \n",
      "..   ...    ...  ..  ..  ...  ..  ..   ...  ...  ...  ...   ...  ...  ...   \n",
      "670  490    NaN  PF  26  TOT  76  68  2434  451  968  ...  .655  127  284   \n",
      "671  490    NaN  PF  26  MIN  48  48  1605  289  641  ...  .682   75  170   \n",
      "672  490    NaN  PF  26  BRK  28  20   829  162  327  ...  .606   52  114   \n",
      "673  491    NaN   C  22  CHO  62  45  1487  172  373  ...  .774   97  265   \n",
      "674  492    NaN   C  25  BOS  82  59  1731  340  619  ...  .823  146  319   \n",
      "\n",
      "     TRB  AST  STL BLK  TOV   PF   PTS  \n",
      "0    301   68   27  22   60  147   398  \n",
      "1     28   16   16   7   14   24    94  \n",
      "2    523   66   38  86   99  222   537  \n",
      "3     77   15    4   9    9   30    60  \n",
      "4    247  129   41   7  116  167  1035  \n",
      "..   ...  ...  ...  ..  ...  ...   ...  \n",
      "670  411  173  124  25  117  171  1071  \n",
      "671  245  135   86  17   75  115   685  \n",
      "672  166   38   38   8   42   56   386  \n",
      "673  362  100   34  49   62  156   472  \n",
      "674  465  113   18  52   76  205   833  \n",
      "\n",
      "[675 rows x 30 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>...</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF</td>\n",
       "      <td>24</td>\n",
       "      <td>NYK</td>\n",
       "      <td>68</td>\n",
       "      <td>22</td>\n",
       "      <td>1287</td>\n",
       "      <td>152</td>\n",
       "      <td>331</td>\n",
       "      <td>...</td>\n",
       "      <td>.784</td>\n",
       "      <td>79</td>\n",
       "      <td>222</td>\n",
       "      <td>301</td>\n",
       "      <td>68</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>147</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SG</td>\n",
       "      <td>20</td>\n",
       "      <td>MEM</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>35</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>.609</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>21</td>\n",
       "      <td>OKC</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>1771</td>\n",
       "      <td>217</td>\n",
       "      <td>399</td>\n",
       "      <td>...</td>\n",
       "      <td>.502</td>\n",
       "      <td>199</td>\n",
       "      <td>324</td>\n",
       "      <td>523</td>\n",
       "      <td>66</td>\n",
       "      <td>38</td>\n",
       "      <td>86</td>\n",
       "      <td>99</td>\n",
       "      <td>222</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PF</td>\n",
       "      <td>28</td>\n",
       "      <td>MIN</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>.579</td>\n",
       "      <td>23</td>\n",
       "      <td>54</td>\n",
       "      <td>77</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SG</td>\n",
       "      <td>29</td>\n",
       "      <td>TOT</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>2502</td>\n",
       "      <td>375</td>\n",
       "      <td>884</td>\n",
       "      <td>...</td>\n",
       "      <td>.843</td>\n",
       "      <td>27</td>\n",
       "      <td>220</td>\n",
       "      <td>247</td>\n",
       "      <td>129</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>116</td>\n",
       "      <td>167</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rk Player Pos Age   Tm   G  GS    MP   FG  FGA  ...   FT%  ORB  DRB  TRB  \\\n",
       "0  1    NaN  PF  24  NYK  68  22  1287  152  331  ...  .784   79  222  301   \n",
       "1  2    NaN  SG  20  MEM  30   0   248   35   86  ...  .609    9   19   28   \n",
       "2  3    NaN   C  21  OKC  70  67  1771  217  399  ...  .502  199  324  523   \n",
       "3  4    NaN  PF  28  MIN  17   0   215   19   44  ...  .579   23   54   77   \n",
       "4  5    NaN  SG  29  TOT  78  72  2502  375  884  ...  .843   27  220  247   \n",
       "\n",
       "   AST STL BLK  TOV   PF   PTS  \n",
       "0   68  27  22   60  147   398  \n",
       "1   16  16   7   14   24    94  \n",
       "2   66  38  86   99  222   537  \n",
       "3   15   4   9    9   30    60  \n",
       "4  129  41   7  116  167  1035  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the file path, column name, and category order\n",
    "file_path = input(\"Enter the file path of the CSV file: \")\n",
    "column_name = input(\"Enter the name of the column to convert: \")\n",
    "category_order = input(\"Enter the category order (comma-separated): \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the specified column to a categorical data type with the specified category order\n",
    "category_order_list = category_order.split(',')\n",
    "df[column_name] = pd.Categorical(df[column_name], categories=category_order_list, ordered=True)\n",
    "\n",
    "# Sort the DataFrame based on the specified column\n",
    "sorted_df = df.sort_values(column_name)\n",
    "\n",
    "# Display the sorted data\n",
    "print(\"Sorted Data:\")\n",
    "print(sorted_df)\n",
    "sorted_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a5a847-2f24-484b-a8e7-8a160c9a98ff",
   "metadata": {},
   "source": [
    "In this program, the user is prompted to enter the file path of the CSV file, the name of the column to convert, and the category order (comma-separated). The CSV file is read into a DataFrame using pd.read_csv().\n",
    "\n",
    "Then, the specified column is converted to a categorical data type using pd.Categorical(). The categories parameter is set to the category_order_list which is created by splitting the input category_order using commas. The ordered parameter is set to True to indicate that the categories have a specific order.\n",
    "\n",
    "After converting the column, the DataFrame is sorted based on the specified column using df.sort_values(). The sorted DataFrame is stored in the sorted_df variable.\n",
    "\n",
    "Finally, the program displays the sorted data using print(sorted_df)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "731f94f2-ea43-450f-a0ad-9dc863c63a1e",
   "metadata": {},
   "source": [
    "Q10. Write a Python program that reads a CSV file containing sales data for different products and\n",
    "visualizes the data using a stacked bar chart to show the sales of each product category over time. The\n",
    "program should prompt the user to enter the file path and display the chart.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b119553-3dc2-4bd6-a2ae-34e614388798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prompt the user to enter the file path of the CSV file\n",
    "file_path = input(\"Enter the file path of the CSV file: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the CSV file has columns 'Date', 'Product_Category', and 'Sales'\n",
    "# If column names differ, modify the code accordingly\n",
    "\n",
    "# Convert the 'Date' column to datetime data type\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group the data by 'Date' and 'Product_Category' and sum the 'Sales' for each category\n",
    "sales_by_category = df.groupby(['Date', 'Product_Category'])['Sales'].sum().unstack()\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = sales_by_category.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "# Set the title and labels for axes\n",
    "plt.title(\"Sales by Product Category over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "\n",
    "# Show the legend\n",
    "plt.legend(title=\"Product Category\", loc='upper left')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1e73ea0-0972-448e-961d-81319ce2eb56",
   "metadata": {},
   "source": [
    "Q11. You are given a CSV file containing student data that includes the student ID and their test score. Write\n",
    "a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and\n",
    "displays the results in a table.\n",
    "The program should do the followingM\n",
    "I Prompt the user to enter the file path of the CSV file containing the student dataR\n",
    "I Read the CSV file into a Pandas DataFrameR\n",
    "I Calculate the mean, median, and mode of the test scores using Pandas toolsR\n",
    "I Display the mean, median, and mode in a table.\n",
    "Assume the CSV file contains the following columnsM\n",
    "I Student ID: The ID of the studentR\n",
    "I Test Score: The score of the student's test.\n",
    "Example usage of the program:\n",
    "Enter the file path of the CSV file containing the student data: student_data.csv\n",
    "+-----------+--------+\n",
    "| Statistic | Value |\n",
    "+-----------+--------+\n",
    "| Mean | 79.6 |\n",
    "| Median | 82 |\n",
    "| Mode | 85, 90 |\n",
    "+-----------+--------+\n",
    "Assume that the CSV file student_data.csv contains the following data:\n",
    "Student ID,Test Score\n",
    "1,85\n",
    "2,90\n",
    "3,80\n",
    "4,75\n",
    "5,85\n",
    "6,82\n",
    "7,78\n",
    "8,85\n",
    "9,90\n",
    "10,85\n",
    "The program should calculate the mean, median, and mode of the test scores and display the results\n",
    "in a table.\n",
    "\n",
    "Ans--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52e4b4-266d-4e04-a217-a3cc40bf7337",
   "metadata": {},
   "source": [
    "To calculate the mean, median, and mode of test scores from a CSV file containing student data and display the results in a table, you can use the pandas library in Python. Here's a Python program that accomplishes this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8f669c5-102d-48ce-b00a-6ea306ade4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student ID  Test Score\n",
      "0           1          85\n",
      "1           2          90\n",
      "2           3          80\n",
      "3           4          75\n",
      "4           5          85\n",
      "5           6          82\n",
      "6           7          78\n",
      "7           8          85\n",
      "8           9          90\n",
      "9          10          85\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Student ID':(1,2,3,4,5,6,7,8,9,10),\n",
    "                          'Test Score':(85,90,80,75,85,82,78,85,90,85)})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f013f2ad-2495-450f-b3b6-4bf7af97b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame called df\n",
    "\n",
    "# Specify the file path and name for the output CSV file\n",
    "output_file = 'df.csv'\n",
    "\n",
    "# Convert the DataFrame to a CSV file\n",
    "df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7926c80e-088a-482d-8302-d8615433347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file path of the CSV file containing the student data:  df.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Statistic Value\n",
      "0      Mean  83.5\n",
      "1    Median  85.0\n",
      "2      Mode    85\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the file path of the CSV file\n",
    "file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate the mean, median, and mode of the test scores\n",
    "mean_score = df['Test Score'].mean()\n",
    "median_score = df['Test Score'].median()\n",
    "mode_scores = df['Test Score'].mode()\n",
    "\n",
    "# Create a dictionary to hold the results\n",
    "results = {\n",
    "    'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "    'Value': [mean_score, median_score, ', '.join(map(str, mode_scores))]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the results dictionary\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results table\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd743802-b904-4510-9f6a-0ae30144b194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
